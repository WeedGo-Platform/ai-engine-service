#!/usr/bin/env python3
"""
Setup script for multilingual model support
Downloads and configures Qwen2.5 for Chinese language support
"""

import os
import sys
import json
import asyncio
import logging
from pathlib import Path
import requests
from tqdm import tqdm

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MultilingualModelSetup:
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.models_dir = self.base_dir / "models" / "multilingual"
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        # Model configurations
        self.models = {
            "qwen2.5-7b-instruct": {
                "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct-GGUF/resolve/main/qwen2.5-7b-instruct-q4_k_m.gguf",
                "size": "4.5GB",
                "languages": ["zh", "en", "es", "fr", "ja", "ko", "ar"],
                "filename": "qwen2.5-7b-instruct-q4_k_m.gguf",
                "description": "Best overall multilingual model with excellent Chinese support"
            },
            "chatglm3-6b": {
                "url": "https://huggingface.co/THUDM/chatglm3-6b-gguf/resolve/main/chatglm3-6b-q4_0.gguf",
                "size": "3.5GB",
                "languages": ["zh", "en"],
                "filename": "chatglm3-6b-q4_0.gguf",
                "description": "Optimized for Chinese conversations"
            }
        }
    
    def download_model(self, model_name: str):
        """Download a specific model"""
        if model_name not in self.models:
            logger.error(f"Unknown model: {model_name}")
            return False
        
        model_info = self.models[model_name]
        output_path = self.models_dir / model_info["filename"]
        
        if output_path.exists():
            logger.info(f"Model already exists: {output_path}")
            return True
        
        logger.info(f"Downloading {model_name} ({model_info['size']})...")
        logger.info(f"URL: {model_info['url']}")
        
        try:
            response = requests.get(model_info["url"], stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(output_path, 'wb') as f:
                with tqdm(total=total_size, unit='iB', unit_scale=True) as pbar:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                        pbar.update(len(chunk))
            
            logger.info(f"Successfully downloaded: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to download {model_name}: {e}")
            if output_path.exists():
                output_path.unlink()
            return False
    
    def create_config(self):
        """Create configuration file for multilingual models"""
        config = {
            "models": {
                "qwen": {
                    "path": str(self.models_dir / "qwen2.5-7b-instruct-q4_k_m.gguf"),
                    "languages": ["zh", "ar", "ja", "ko"],
                    "context_size": 4096,
                    "gpu_layers": 35,
                    "threads": 8,
                    "temperature": 0.7,
                    "max_tokens": 512
                },
                "mistral": {
                    "path": str(self.base_dir / "models" / "base" / "mistral-7b-instruct-v0.2.Q4_K_M.gguf"),
                    "languages": ["en", "es", "fr", "pt"],
                    "context_size": 4096,
                    "gpu_layers": 35,
                    "threads": 8,
                    "temperature": 0.7,
                    "max_tokens": 512
                }
            },
            "language_routing": {
                "zh": "qwen",
                "zh-cn": "qwen",
                "zh-tw": "qwen",
                "ar": "qwen",
                "ja": "qwen",
                "ko": "qwen",
                "en": "mistral",
                "es": "mistral",
                "fr": "mistral",
                "pt": "mistral"
            },
            "prompts": {
                "zh": {
                    "system": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤§éº»äº§å“é¡¾é—®ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”å®¢æˆ·å…³äºå¤§éº»äº§å“çš„é—®é¢˜ã€‚è®°ä½è¦ï¼š1) æä¾›å‡†ç¡®çš„äº§å“ä¿¡æ¯ 2) è§£é‡Šä¸åŒå“ç§çš„æ•ˆæœ 3) æ ¹æ®å®¢æˆ·éœ€æ±‚æ¨èåˆé€‚çš„äº§å“ 4) ä¿æŒä¸“ä¸šå’Œå‹å¥½çš„æ€åº¦",
                    "greeting": "æ‚¨å¥½ï¼æ¬¢è¿å…‰ä¸´ã€‚æˆ‘å¯ä»¥å¸®æ‚¨æ¨èé€‚åˆçš„å¤§éº»äº§å“ã€‚è¯·é—®æ‚¨åœ¨å¯»æ‰¾ä»€ä¹ˆç±»å‹çš„äº§å“å‘¢ï¼Ÿ"
                },
                "ar": {
                    "system": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù…Ø­ØªØ±Ù Ù„Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù‚Ù†Ø¨. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø­ÙˆÙ„ Ù…Ù†ØªØ¬Ø§Øª Ø§Ù„Ù‚Ù†Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.",
                    "greeting": "Ù…Ø±Ø­Ø¨Ø§Ù‹! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"
                }
            }
        }
        
        config_path = self.base_dir / "config" / "multilingual_models.json"
        config_path.parent.mkdir(exist_ok=True)
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Created config file: {config_path}")
        return config_path
    
    def test_model(self, model_name: str = "qwen"):
        """Test the multilingual model with Chinese queries"""
        try:
            from llama_cpp import Llama
            
            model_path = self.models_dir / "qwen2.5-7b-instruct-q4_k_m.gguf"
            if not model_path.exists():
                logger.error(f"Model not found: {model_path}")
                return False
            
            logger.info("Loading Qwen model for testing...")
            model = Llama(
                model_path=str(model_path),
                n_ctx=2048,
                n_threads=4,
                n_gpu_layers=0  # CPU only for testing
            )
            
            # Test queries
            test_queries = [
                "æœ€é«˜THCå«é‡çš„äº§å“æ˜¯ä»€ä¹ˆï¼Ÿ",
                "æ¨èä¸€äº›é€‚åˆæ–°æ‰‹çš„äº§å“",
                "indicaå’Œsativaæœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"
            ]
            
            for query in test_queries:
                logger.info(f"\nQuery: {query}")
                
                prompt = f"""<|im_start|>system
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤§éº»äº§å“é¡¾é—®ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”å®¢æˆ·çš„é—®é¢˜ã€‚
<|im_end|>
<|im_start|>user
{query}
<|im_end|>
<|im_start|>assistant
"""
                
                response = model(
                    prompt,
                    max_tokens=256,
                    temperature=0.7,
                    stop=["<|im_end|>"]
                )
                
                answer = response['choices'][0]['text']
                logger.info(f"Response: {answer[:200]}...")
            
            return True
            
        except ImportError:
            logger.error("llama-cpp-python not installed. Install with: pip install llama-cpp-python")
            return False
        except Exception as e:
            logger.error(f"Model testing failed: {e}")
            return False
    
    def setup_chinese_cannabis_vocabulary(self):
        """Create Chinese cannabis terminology database"""
        vocabulary = {
            "strains": {
                "sativa": {"zh": "è¨è’‚ç“¦", "pinyin": "sÃ  dÃ¬ wÇ", "description": "æç¥å‹å“ç§"},
                "indica": {"zh": "å°åº¦å¤§éº»", "pinyin": "yÃ¬n dÃ¹ dÃ  mÃ¡", "description": "æ”¾æ¾å‹å“ç§"},
                "hybrid": {"zh": "æ··åˆå“ç§", "pinyin": "hÃ¹n hÃ© pÇn zhÇ’ng", "description": "æ··åˆæ•ˆæœ"}
            },
            "products": {
                "flower": {"zh": "èŠ±", "pinyin": "huÄ", "description": "å¹²ç‡¥å¤§éº»èŠ±"},
                "edibles": {"zh": "é£Ÿç”¨å“", "pinyin": "shÃ­ yÃ²ng pÇn", "description": "å¯é£Ÿç”¨äº§å“"},
                "vape": {"zh": "ç”µå­çƒŸ", "pinyin": "diÃ n zÇ yÄn", "description": "è’¸æ±½äº§å“"},
                "concentrate": {"zh": "æµ“ç¼©ç‰©", "pinyin": "nÃ³ng suÅ wÃ¹", "description": "é«˜æµ“åº¦æå–ç‰©"},
                "pre-roll": {"zh": "é¢„å·çƒŸ", "pinyin": "yÃ¹ juÇn yÄn", "description": "é¢„å…ˆå·å¥½çš„å¤§éº»çƒŸ"}
            },
            "effects": {
                "relaxing": {"zh": "æ”¾æ¾", "pinyin": "fÃ ng sÅng"},
                "energizing": {"zh": "æç¥", "pinyin": "tÃ­ shÃ©n"},
                "euphoric": {"zh": "æ¬£å¿«", "pinyin": "xÄ«n kuÃ i"},
                "creative": {"zh": "åˆ›é€ æ€§", "pinyin": "chuÃ ng zÃ o xÃ¬ng"},
                "focused": {"zh": "ä¸“æ³¨", "pinyin": "zhuÄn zhÃ¹"},
                "sleepy": {"zh": "å›°å€¦", "pinyin": "kÃ¹n juÃ n"}
            },
            "compounds": {
                "THC": {"zh": "å››æ°¢å¤§éº»é…š", "pinyin": "sÃ¬ qÄ«ng dÃ  mÃ¡ fÄ“n", "description": "ç²¾ç¥æ´»æ€§æˆåˆ†"},
                "CBD": {"zh": "å¤§éº»äºŒé…š", "pinyin": "dÃ  mÃ¡ Ã¨r fÄ“n", "description": "éç²¾ç¥æ´»æ€§æˆåˆ†"},
                "terpenes": {"zh": "èœçƒ¯", "pinyin": "tiÄ“ xÄ«", "description": "é¦™å‘³åŒ–åˆç‰©"}
            }
        }
        
        vocab_path = self.base_dir / "data" / "chinese_cannabis_vocabulary.json"
        vocab_path.parent.mkdir(exist_ok=True)
        
        with open(vocab_path, 'w', encoding='utf-8') as f:
            json.dump(vocabulary, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Created Chinese vocabulary: {vocab_path}")
        return vocabulary

def main():
    """Main setup function"""
    setup = MultilingualModelSetup()
    
    print("\nğŸŒ WeedGo Multilingual Model Setup")
    print("=" * 50)
    
    # Show available models
    print("\nAvailable models:")
    for name, info in setup.models.items():
        print(f"  â€¢ {name}: {info['description']}")
        print(f"    Size: {info['size']}, Languages: {', '.join(info['languages'])}")
    
    # Ask which model to download
    print("\nWhich model would you like to set up?")
    print("1. Qwen2.5-7B (Recommended - Best multilingual)")
    print("2. ChatGLM3-6B (Chinese optimized)")
    print("3. Both")
    print("4. Skip download (configure only)")
    
    choice = input("\nEnter choice (1-4): ").strip()
    
    if choice == "1":
        setup.download_model("qwen2.5-7b-instruct")
    elif choice == "2":
        setup.download_model("chatglm3-6b")
    elif choice == "3":
        setup.download_model("qwen2.5-7b-instruct")
        setup.download_model("chatglm3-6b")
    
    # Create configuration
    print("\nğŸ“ Creating configuration...")
    setup.create_config()
    
    # Set up vocabulary
    print("\nğŸ“š Setting up Chinese cannabis vocabulary...")
    setup.setup_chinese_cannabis_vocabulary()
    
    # Test if requested
    test = input("\nğŸ§ª Would you like to test the model? (y/n): ").strip().lower()
    if test == 'y':
        setup.test_model()
    
    print("\nâœ… Setup complete!")
    print("\nNext steps:")
    print("1. Update smart_multilingual_engine.py to use Qwen for Chinese")
    print("2. Restart the AI service")
    print("3. Test with Chinese queries")

if __name__ == "__main__":
    main()