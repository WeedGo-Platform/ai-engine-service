import React, { useState, useEffect, useRef, useCallback } from 'react';
import {
  MessageCircle,
  X,
  Send,
  Minimize2,
  Bot,
  User,
  Clock,
  Mic,
  MicOff,
  Volume2,
  VolumeX,
  Loader2,
  AlertCircle,
  PenLine
} from 'lucide-react';
import { voiceApi } from '../services/voiceApi';

type RecordingState = 'idle' | 'recording' | 'processing' | 'error';

interface Message {
  id: string;
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: Date;
  responseTime?: number;
  tokens?: number;
  isVoice?: boolean;
}

interface SalesChatWidgetProps {
  wsUrl?: string;
  enableVoice?: boolean;
}

// Sales-focused busy activities
const busyActivities = [
  { icon: 'ğŸ’¡', text: 'Analyzing your needs' },
  { icon: 'ğŸ“Š', text: 'Checking pricing options' },
  { icon: 'ğŸ¯', text: 'Finding the perfect fit' },
  { icon: 'âœ¨', text: 'Preparing recommendations' },
  { icon: 'ğŸš€', text: 'Finalizing details' }
];

// Simple markdown renderer for bold text
const renderMarkdown = (text: string): string => {
  // Convert **text** to <strong>text</strong>
  let rendered = text.replace(/\*\*(.+?)\*\*/g, '<strong>$1</strong>');
  // Convert newlines to <br/>
  rendered = rendered.replace(/\n/g, '<br/>');
  return rendered;
};

// Strip markdown for TTS - remove formatting but keep the text
const stripMarkdown = (text: string): string => {
  // Remove **bold** markers (keep the text inside)
  let cleaned = text.replace(/\*\*(.+?)\*\*/g, '$1');
  // Remove *italic* markers
  cleaned = cleaned.replace(/\*(.+?)\*/g, '$1');
  // Remove __bold__ markers
  cleaned = cleaned.replace(/__(.+?)__/g, '$1');
  // Remove _italic_ markers
  cleaned = cleaned.replace(/_(.+?)_/g, '$1');
  // Remove # headings
  cleaned = cleaned.replace(/^#{1,6}\s+/gm, '');
  // Remove [links](url) - keep just the link text
  cleaned = cleaned.replace(/\[(.+?)\]\(.+?\)/g, '$1');
  // Remove backticks for code
  cleaned = cleaned.replace(/`(.+?)`/g, '$1');
  return cleaned;
};

// Greeting translations for common languages
const GREETING_TRANSLATIONS: Record<string, string> = {
  en: "Hi! I'm Carlos, your WeedGo sales assistant. ğŸ‘‹\n\nI'm here to help you discover how WeedGo can transform your cannabis retail business. Whether you're curious about pricing, features, or just getting started - I'm here to answer any questions.\n\nWhat would you like to know about WeedGo?",
  
  es: "Â¡Hola! Soy Carlos, tu asistente de ventas de WeedGo. ğŸ‘‹\n\nEstoy aquÃ­ para ayudarte a descubrir cÃ³mo WeedGo puede transformar tu negocio de cannabis. Ya sea que tengas curiosidad sobre precios, caracterÃ­sticas o estÃ©s comenzando - estoy aquÃ­ para responder cualquier pregunta.\n\nÂ¿QuÃ© te gustarÃ­a saber sobre WeedGo?",
  
  fr: "Bonjour ! Je suis Carlos, votre assistant commercial WeedGo. ğŸ‘‹\n\nJe suis lÃ  pour vous aider Ã  dÃ©couvrir comment WeedGo peut transformer votre entreprise de cannabis. Que vous soyez curieux des prix, des fonctionnalitÃ©s ou que vous dÃ©butiez - je suis lÃ  pour rÃ©pondre Ã  toutes vos questions.\n\nQu'aimeriez-vous savoir sur WeedGo ?",
  
  de: "Hallo! Ich bin Carlos, Ihr WeedGo-Verkaufsassistent. ğŸ‘‹\n\nIch bin hier, um Ihnen zu helfen, herauszufinden, wie WeedGo Ihr Cannabis-EinzelhandelsgeschÃ¤ft transformieren kann. Egal, ob Sie neugierig auf Preise, Funktionen oder den Einstieg sind - ich bin hier, um alle Fragen zu beantworten.\n\nWas mÃ¶chten Sie Ã¼ber WeedGo erfahren?",
  
  zh: "ä½ å¥½ï¼æˆ‘æ˜¯Carlosï¼Œæ‚¨çš„WeedGoé”€å”®åŠ©æ‰‹ã€‚ğŸ‘‹\n\næˆ‘åœ¨è¿™é‡Œå¸®åŠ©æ‚¨äº†è§£WeedGoå¦‚ä½•æ”¹å˜æ‚¨çš„å¤§éº»é›¶å”®ä¸šåŠ¡ã€‚æ— è®ºæ‚¨å¯¹ä»·æ ¼ã€åŠŸèƒ½æ„Ÿåˆ°å¥½å¥‡ï¼Œè¿˜æ˜¯åˆšåˆšå¼€å§‹ - æˆ‘éƒ½åœ¨è¿™é‡Œå›ç­”ä»»ä½•é—®é¢˜ã€‚\n\næ‚¨æƒ³äº†è§£WeedGoçš„ä»€ä¹ˆï¼Ÿ",
  
  ja: "ã“ã‚“ã«ã¡ã¯ï¼ç§ã¯Carlosã§ã™ã€ã‚ãªãŸã®WeedGoè²©å£²ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ğŸ‘‹\n\nWeedGoãŒã‚ãªãŸã®å¤§éº»å°å£²ãƒ“ã‚¸ãƒã‚¹ã‚’ã©ã®ã‚ˆã†ã«å¤‰é©ã§ãã‚‹ã‹ã‚’ãŠæ‰‹ä¼ã„ã—ã¾ã™ã€‚ä¾¡æ ¼ã€æ©Ÿèƒ½ã€ã¾ãŸã¯å§‹ã‚æ–¹ã«ã¤ã„ã¦èˆˆå‘³ãŒã‚ã‚‹å ´åˆ - ã©ã‚“ãªè³ªå•ã«ã‚‚ãŠç­”ãˆã—ã¾ã™ã€‚\n\nWeedGoã«ã¤ã„ã¦ä½•ã‚’çŸ¥ã‚ŠãŸã„ã§ã™ã‹ï¼Ÿ",
  
  ko: "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Carlosì…ë‹ˆë‹¤, WeedGo ì˜ì—… ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ğŸ‘‹\n\nWeedGoê°€ ê·€í•˜ì˜ ëŒ€ë§ˆì´ˆ ì†Œë§¤ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ì–´ë–»ê²Œ ë³€í™”ì‹œí‚¬ ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³´ëŠ” ê²ƒì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤. ê°€ê²©, ê¸°ëŠ¥ ë˜ëŠ” ì‹œì‘í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ê²½ìš° - ëª¨ë“  ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤.\n\nWeedGoì— ëŒ€í•´ ë¬´ì—‡ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
  
  pt: "OlÃ¡! Sou Carlos, seu assistente de vendas WeedGo. ğŸ‘‹\n\nEstou aqui para ajudÃ¡-lo a descobrir como o WeedGo pode transformar seu negÃ³cio de varejo de cannabis. Seja curioso sobre preÃ§os, recursos ou apenas comeÃ§ando - estou aqui para responder a qualquer pergunta.\n\nO que vocÃª gostaria de saber sobre o WeedGo?",
  
  ru: "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ Carlos, Ğ²Ğ°Ñˆ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº WeedGo. ğŸ‘‹\n\nĞ¯ Ğ·Ğ´ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‡ÑŒ Ğ²Ğ°Ğ¼ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ, ĞºĞ°Ğº WeedGo Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ°Ñˆ Ñ€Ğ¾Ğ·Ğ½Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ğ±Ğ¸Ğ·Ğ½ĞµÑ ĞºĞ°Ğ½Ğ½Ğ°Ğ±Ğ¸ÑĞ°. Ğ‘ÑƒĞ´ÑŒ Ñ‚Ğ¾ Ñ†ĞµĞ½Ñ‹, Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ¸Ğ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ - Ñ Ğ·Ğ´ĞµÑÑŒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ° Ğ»ÑĞ±Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹.\n\nĞ§Ñ‚Ğ¾ Ğ±Ñ‹ Ğ²Ñ‹ Ñ…Ğ¾Ñ‚ĞµĞ»Ğ¸ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ Ğ¾ WeedGo?",
  
  ar: "Ù…Ø±Ø­Ø¨Ù‹Ø§! Ø£Ù†Ø§ CarlosØŒ Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨ÙŠØ¹Ø§Øª WeedGo Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ. ğŸ‘‹\n\nØ£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù ÙƒÙŠÙ ÙŠÙ…ÙƒÙ† Ù„Ù€ WeedGo ØªØ­ÙˆÙŠÙ„ Ø£Ø¹Ù…Ø§Ù„ ØªØ¬Ø§Ø±Ø© Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ. Ø³ÙˆØ§Ø¡ ÙƒÙ†Øª ÙØ¶ÙˆÙ„ÙŠÙ‹Ø§ Ø¨Ø´Ø£Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø£Ùˆ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø£Ùˆ Ø§Ù„Ø¨Ø¯Ø¡ ÙÙ‚Ø· - Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£ÙŠ Ø£Ø³Ø¦Ù„Ø©.\n\nÙ…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† ØªØ¹Ø±Ù Ø¹Ù† WeedGoØŸ",
  
  it: "Ciao! Sono Carlos, il tuo assistente alle vendite WeedGo. ğŸ‘‹\n\nSono qui per aiutarti a scoprire come WeedGo puÃ² trasformare la tua attivitÃ  al dettaglio di cannabis. Che tu sia curioso di prezzi, funzionalitÃ  o appena iniziato - sono qui per rispondere a qualsiasi domanda.\n\nCosa vorresti sapere su WeedGo?",
  
  nl: "Hallo! Ik ben Carlos, uw WeedGo-verkoopassistent. ğŸ‘‹\n\nIk ben hier om u te helpen ontdekken hoe WeedGo uw cannabisdetailhandel kan transformeren. Of u nu nieuwsgierig bent naar prijzen, functies of net begint - ik ben hier om elke vraag te beantwoorden.\n\nWat wilt u weten over WeedGo?",
  
  pl: "CzeÅ›Ä‡! Jestem Carlos, TwÃ³j asystent sprzedaÅ¼y WeedGo. ğŸ‘‹\n\nJestem tutaj, aby pomÃ³c Ci odkryÄ‡, jak WeedGo moÅ¼e przeksztaÅ‚ciÄ‡ TwÃ³j biznes detaliczny z konopiÄ…. Czy jesteÅ› ciekawy cen, funkcji czy dopiero zaczynasz - jestem tutaj, aby odpowiedzieÄ‡ na wszystkie pytania.\n\nCo chciaÅ‚byÅ› wiedzieÄ‡ o WeedGo?",
  
  tr: "Merhaba! Ben Carlos, WeedGo satÄ±ÅŸ asistanÄ±nÄ±zÄ±m. ğŸ‘‹\n\nWeedGo'nun esrar perakende iÅŸinizi nasÄ±l dÃ¶nÃ¼ÅŸtÃ¼rebileceÄŸini keÅŸfetmenize yardÄ±mcÄ± olmak iÃ§in buradayÄ±m. Fiyatlar, Ã¶zellikler veya sadece baÅŸlama konusunda meraklÄ±ysanÄ±z - herhangi bir soruya cevap vermek iÃ§in buradayÄ±m.\n\nWeedGo hakkÄ±nda ne Ã¶ÄŸrenmek istersiniz?",
  
  vi: "Xin chÃ o! TÃ´i lÃ  Carlos, trá»£ lÃ½ bÃ¡n hÃ ng WeedGo cá»§a báº¡n. ğŸ‘‹\n\nTÃ´i á»Ÿ Ä‘Ã¢y Ä‘á»ƒ giÃºp báº¡n khÃ¡m phÃ¡ cÃ¡ch WeedGo cÃ³ thá»ƒ biáº¿n Ä‘á»•i doanh nghiá»‡p bÃ¡n láº» cáº§n sa cá»§a báº¡n. Cho dÃ¹ báº¡n tÃ² mÃ² vá» giÃ¡ cáº£, tÃ­nh nÄƒng hay chá»‰ má»›i báº¯t Ä‘áº§u - tÃ´i á»Ÿ Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i báº¥t ká»³ cÃ¢u há»i nÃ o.\n\nBáº¡n muá»‘n biáº¿t gÃ¬ vá» WeedGo?"
};

// Default greeting message (English fallback)
const DEFAULT_GREETING = GREETING_TRANSLATIONS.en;

const SalesChatWidget: React.FC<SalesChatWidgetProps> = ({
  wsUrl = 'ws://localhost:5024/api/v1/chat/ws',
  enableVoice = true
}) => {
  // Fixed agent and personality for sales
  const AGENT = 'sales';
  const PERSONALITY = 'carlos';

  // UI State
  const [isOpen, setIsOpen] = useState(false);
  const [isMinimized, setIsMinimized] = useState(false);

  // Chat State
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputMessage, setInputMessage] = useState('');
  const [isTyping, setIsTyping] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [sessionId, setSessionId] = useState<string | null>(null);
  const [currentActivity, setCurrentActivity] = useState(busyActivities[0]);
  const [isBusy, setIsBusy] = useState(false);

  // Translation State
  const [greetingMessage, setGreetingMessage] = useState<string>(DEFAULT_GREETING);

  const messageStartTimeRef = useRef<number | null>(null);
  const messageIdCounter = useRef<number>(0);

  // Generate unique message IDs
  const generateMessageId = () => {
    messageIdCounter.current += 1;
    return `msg-${Date.now()}-${messageIdCounter.current}`;
  };

  // Voice State
  const [voiceState, setVoiceState] = useState<RecordingState>('idle');
  const [voicePermission, setVoicePermission] = useState<boolean>(false);
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState<string>('');
  const [liveTranscript, setLiveTranscript] = useState<string>('');
  const silenceTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const pauseTimerRef = useRef<ReturnType<typeof setTimeout> | null>(null);
  const lastSpeechTimeRef = useRef<number>(Date.now());
  const pendingTranscriptRef = useRef<string>('');
  const sendMessageRef = useRef<(text: string) => void>();

  // TTS State
  const [isSpeakerEnabled, setIsSpeakerEnabled] = useState<boolean>(() => {
    const saved = localStorage.getItem('salesChatWidgetTTSEnabled');
    return saved === 'true';
  });
  const [isSpeaking, setIsSpeaking] = useState<boolean>(false);
  const currentAudioRef = useRef<HTMLAudioElement | null>(null);

  // Typing Animation State
  const [typingMessages, setTypingMessages] = useState<Map<string, string>>(new Map());
  const typingAnimationsRef = useRef<Map<string, boolean>>(new Map());

  // Web Speech API Recognition
  const [recognition, setRecognition] = useState<any>(null);
  const [isTranscribing, setIsTranscribing] = useState<boolean>(false);

  // Refs
  const ws = useRef<WebSocket | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const inputRef = useRef<HTMLTextAreaElement>(null);
  const activityInterval = useRef<NodeJS.Timeout | null>(null);

  // Initialize Web Speech API
  useEffect(() => {
    if (enableVoice && ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();

      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';
      recognition.maxAlternatives = 1;

      let allFinalText = '';
      let lastResultIndex = 0;
      let lastSentText = '';

      recognition.onstart = () => {
        console.log('Speech recognition started');
        setVoiceState('recording');
        setIsRecording(true);
        setIsTranscribing(true);
        lastSpeechTimeRef.current = Date.now();
      };

      recognition.onresult = (event: any) => {
        let interimText = '';
        let newFinalText = '';

        for (let i = lastResultIndex; i < event.results.length; i++) {
          const result = event.results[i];
          if (!result || !result[0]) continue;

          const transcriptText = String(result[0].transcript);

          if (result.isFinal) {
            newFinalText += transcriptText + ' ';
            if (i >= lastResultIndex) {
              allFinalText += transcriptText + ' ';
              lastResultIndex = i + 1;
            }
          } else {
            interimText = transcriptText;
          }
        }

        const completeTranscript = allFinalText + interimText;
        setTranscript(completeTranscript);
        setLiveTranscript(interimText);
        pendingTranscriptRef.current = allFinalText;
        setIsTranscribing(interimText.length > 0 || allFinalText.length > 0);
        lastSpeechTimeRef.current = Date.now();

        // Clear existing timers
        if (pauseTimerRef.current) {
          clearTimeout(pauseTimerRef.current);
          pauseTimerRef.current = null;
        }
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current);
          silenceTimerRef.current = null;
        }

        // Set new timers if we have text
        if (allFinalText && allFinalText.trim()) {
          pauseTimerRef.current = setTimeout(() => {
            const textToSend = allFinalText.trim();
            if (textToSend && textToSend !== lastSentText) {
              console.log('Sending transcript after pause:', textToSend);
              sendMessageRef.current?.(textToSend);
              lastSentText = textToSend;
              // Reset state for next recording
              allFinalText = '';
              lastResultIndex = event.results.length;
              setTranscript('');
              setLiveTranscript('');
              pendingTranscriptRef.current = '';
            }
          }, 2000);
        }

        silenceTimerRef.current = setTimeout(() => {
          console.log('Auto-stopping due to silence');
          const remainingText = allFinalText.trim();
          if (remainingText && remainingText !== lastSentText) {
            console.log('Sending remaining transcript before stop:', remainingText);
            sendMessageRef.current?.(remainingText);
            lastSentText = remainingText;
          }
          recognition.stop();
          // Reset state after stopping
          setTimeout(() => {
            setTranscript('');
            setLiveTranscript('');
            allFinalText = '';
            lastResultIndex = 0;
            lastSentText = '';
            pendingTranscriptRef.current = '';
          }, 500);
        }, 2000);
      };

      recognition.onend = () => {
        console.log('Speech recognition ended');
        setVoiceState('idle');
        setIsRecording(false);
        setIsTranscribing(false);

        // Clean up timers
        if (pauseTimerRef.current) {
          clearTimeout(pauseTimerRef.current);
          pauseTimerRef.current = null;
        }
        if (silenceTimerRef.current) {
          clearTimeout(silenceTimerRef.current);
          silenceTimerRef.current = null;
        }

        // Reset state variables for next use
        allFinalText = '';
        lastResultIndex = 0;
        lastSentText = '';
      };

      recognition.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setVoiceState('error');
        setIsRecording(false);
        setIsTranscribing(false);
        if (pauseTimerRef.current) clearTimeout(pauseTimerRef.current);
        if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);
      };

      recognition.onend = () => {
        console.log('Speech recognition ended');
        setVoiceState('idle');
        setIsRecording(false);
        setIsTranscribing(false);
        if (pauseTimerRef.current) clearTimeout(pauseTimerRef.current);
        if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);
      };

      setRecognition(recognition);
      setVoicePermission(true);
    }
  }, [enableVoice]);

  // Detect browser language and set greeting
  useEffect(() => {
    const detectLanguageAndSetGreeting = () => {
      try {
        // Get browser language
        const browserLang = navigator.language || navigator.languages?.[0] || 'en';
        
        // Extract language code (e.g., 'en-US' -> 'en', 'zh-CN' -> 'zh')
        const langCode = browserLang.split('-')[0].toLowerCase();

        // Use pre-translated greeting if available, otherwise English
        const greeting = GREETING_TRANSLATIONS[langCode] || GREETING_TRANSLATIONS.en;
        setGreetingMessage(greeting);
        
        console.log(`[SalesChatWidget] Using ${langCode} greeting`);
      } catch (error) {
        // Fallback to English on any error
        console.error('[SalesChatWidget] Error detecting language:', error);
        setGreetingMessage(DEFAULT_GREETING);
      }
    };

    detectLanguageAndSetGreeting();
  }, []); // Run once on mount

  // Auto-scroll to bottom
  const scrollToBottom = useCallback(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, []);

  // Scroll when messages change
  useEffect(() => {
    scrollToBottom();
  }, [messages, scrollToBottom]);

  // Scroll when typing/busy state changes (model thinking or responding)
  useEffect(() => {
    if (isTyping || isBusy) {
      scrollToBottom();
    }
  }, [isTyping, isBusy, scrollToBottom]);

  // Scroll during typing animation
  useEffect(() => {
    if (typingMessages.size > 0) {
      scrollToBottom();
    }
  }, [typingMessages, scrollToBottom]);

  // WebSocket connection management
  useEffect(() => {
    if (isOpen && !ws.current) {
      connectWebSocket();
    }

    return () => {
      if (ws.current) {
        ws.current.close();
        ws.current = null;
      }
      if (activityInterval.current) {
        clearInterval(activityInterval.current);
      }
    };
  }, [isOpen]);

  const connectWebSocket = () => {
    ws.current = new WebSocket(wsUrl);

    ws.current.onopen = () => {
      setIsConnected(true);
      console.log('Connected to sales chat service');

      // Send initial session configuration locked to sales/carlos
      if (ws.current?.readyState === WebSocket.OPEN) {
        ws.current.send(JSON.stringify({
          type: 'session_update',
          agent: AGENT,
          personality: PERSONALITY
        }));
      }
    };

    ws.current.onmessage = (event) => {
      const data = JSON.parse(event.data);
      handleWebSocketMessage(data);
    };

    ws.current.onerror = (error) => {
      console.error('WebSocket error:', error);
      setIsConnected(false);
    };

    ws.current.onclose = () => {
      setIsConnected(false);
      ws.current = null;
      console.log('Disconnected from sales chat service');

      setTimeout(() => {
        if (isOpen) {
          connectWebSocket();
        }
      }, 3000);
    };
  };

  const handleWebSocketMessage = (data: any) => {
    switch (data.type) {
      case 'connection':
        setSessionId(data.session_id);
        // Carlos's greeting - using translated version based on browser language
        setMessages([{
          id: generateMessageId(),
          role: 'assistant',
          content: greetingMessage,
          timestamp: new Date()
        }]);
        break;

      case 'typing':
        // Backend sends: {type: 'typing', typing: true/false}
        const isTypingNow = data.typing === true;
        setIsTyping(isTypingNow);
        setIsBusy(isTypingNow);
        if (isTypingNow) {
          messageStartTimeRef.current = Date.now();
          startActivityRotation();
        } else {
          stopActivityRotation();
        }
        break;

      case 'response':
      case 'message':
        handleIncomingMessage({ ...data, role: 'assistant' });
        break;

      case 'error':
        handleError(data.message || data.error || data.detail || 'An unknown error occurred');
        break;

      case 'session_updated':
        console.log('[SalesChatWidget] Session updated:', data);
        break;

      default:
        console.log('[SalesChatWidget] Unhandled message:', data.type);
    }
  };

  // Typing animation function - simulates human typing
  const animateTyping = async (messageId: string, fullText: string): Promise<void> => {
    return new Promise(async (resolve) => {
      // Mark this message as animating
      typingAnimationsRef.current.set(messageId, true);

      const words = fullText.split(' ');

      for (let i = 0; i <= words.length; i++) {
        // Check if animation was cancelled
        if (!typingAnimationsRef.current.get(messageId)) {
          break;
        }

        const partial = words.slice(0, i).join(' ');
        setTypingMessages(prev => {
          const newMap = new Map(prev);
          newMap.set(messageId, partial);
          return newMap;
        });

        // Don't delay after the last word
        if (i < words.length) {
          // Variable delay: 50-150ms per word (simulates human typing)
          const baseDelay = 50 + Math.random() * 100;

          // Add extra pause after punctuation for natural rhythm
          const extraPause = words[i - 1]?.match(/[.!?]$/) ? 300 : 0;

          await new Promise(resolve => setTimeout(resolve, baseDelay + extraPause));
        }
      }

      // Clean up - remove from typing state
      setTypingMessages(prev => {
        const newMap = new Map(prev);
        newMap.delete(messageId);
        return newMap;
      });
      typingAnimationsRef.current.delete(messageId);

      resolve();
    });
  };

  const handleIncomingMessage = async (data: any) => {
    setIsTyping(false);
    setIsBusy(false);
    stopActivityRotation();
    messageStartTimeRef.current = null;

    // Debug: Log the full data to see what backend sends
    console.log('[DEBUG] Incoming message data:', JSON.stringify(data, null, 2));

    const fullContent = data.content || data.message;
    if (!fullContent) {
      console.warn('[DEBUG] Message has no content:', data);
      return;
    }

    // Handle both assistant and system messages
    if (data.role === 'assistant' || data.role === 'system') {
      const responseTime = data.response_time;
      // Backend sends 'token_count' not 'tokens', also check metadata
      const tokens = data.token_count || data.tokens || data.metadata?.tokens_used || 0;

      console.log('[DEBUG] Extracted tokens:', tokens, 'from:', {
        token_count: data.token_count,
        tokens: data.tokens,
        'metadata.tokens_used': data.metadata?.tokens_used
      });

      const newMessage: Message = {
        id: data.id || generateMessageId(),
        role: data.role === 'system' ? 'system' : 'assistant',
        content: fullContent,
        timestamp: new Date(),
        responseTime,
        tokens
      };

      setMessages(prev => [...prev, newMessage]);
      messageStartTimeRef.current = null;

      // Only do typing animation and TTS for assistant messages, not system messages
      if (data.role === 'assistant') {
        // Start typing animation (don't await - let it run in background)
        animateTyping(newMessage.id, fullContent);

        // Handle TTS if enabled (start IMMEDIATELY, concurrent with typing)
        if (isSpeakerEnabled && fullContent) {
          // Run TTS synthesis and playback concurrently with typing animation
          (async () => {
            try {
              // Strip markdown before TTS to avoid reading "asterisk asterisk"
              const cleanContent = stripMarkdown(fullContent);
              console.log('[TTS] Synthesizing speech for:', cleanContent.substring(0, 50) + '...');
              const audioBlob = await voiceApi.synthesize(cleanContent);
              console.log('[TTS] Audio blob received:', audioBlob.size, 'bytes, type:', audioBlob.type);

              const audioUrl = URL.createObjectURL(audioBlob);
              console.log('[TTS] Audio URL created:', audioUrl);

              if (currentAudioRef.current) {
                currentAudioRef.current.pause();
                currentAudioRef.current = null;
              }

              const audio = new Audio(audioUrl);
              currentAudioRef.current = audio;

              setIsSpeaking(true);
              audio.onended = () => {
                setIsSpeaking(false);
                URL.revokeObjectURL(audioUrl);
                currentAudioRef.current = null;
                // Keep speaker enabled - let user control it manually
                console.log('ğŸ”Š Audio playback completed, speaker remains enabled');
              };

              audio.onerror = () => {
                setIsSpeaking(false);
                URL.revokeObjectURL(audioUrl);
                currentAudioRef.current = null;
              };

              // Play audio immediately (concurrent with typing animation)
              console.log('[TTS] Starting audio playback (concurrent with typing)...');
              await audio.play();
              console.log('[TTS] Audio playing successfully');
            } catch (error: any) {
              console.error('[TTS] Error:', error);
              console.error('[TTS] Error details:', {
                message: error.message,
                name: error.name,
                stack: error.stack
              });
              setIsSpeaking(false);
            }
          })();
        }
      }
    } else {
      console.warn('[DEBUG] Unhandled message role:', data.role);
    }
  };

  const handleError = (message: string | undefined) => {
    setIsTyping(false);
    setIsBusy(false);
    stopActivityRotation();

    const errorMessage = message || 'An unknown error occurred';
    console.error('[SalesChatWidget] Error:', errorMessage);
    
    setMessages(prev => [...prev, {
      id: generateMessageId(),
      role: 'system',
      content: `Error: ${errorMessage}`,
      timestamp: new Date()
    }]);
  };

  const startActivityRotation = () => {
    if (activityInterval.current) return;
    activityInterval.current = setInterval(() => {
      setCurrentActivity(busyActivities[Math.floor(Math.random() * busyActivities.length)]);
    }, 1500);
  };

  const stopActivityRotation = () => {
    if (activityInterval.current) {
      clearInterval(activityInterval.current);
      activityInterval.current = null;
    }
  };

  const sendMessage = (content?: string) => {
    const messageToSend = content || inputMessage.trim();
    if (!messageToSend || !ws.current || !isConnected || isBusy) return;

    const userMessage: Message = {
      id: generateMessageId(),
      role: 'user',
      content: messageToSend,
      timestamp: new Date(),
      isVoice: !!content
    };
    setMessages(prev => [...prev, userMessage]);

    setIsBusy(true);
    messageStartTimeRef.current = Date.now();

    const messagePayload = {
      type: 'message',
      message: messageToSend,
      session_id: sessionId,
      max_tokens: 2000  // Allow longer responses for sales conversations (default was 500)
    };

    if (ws.current.readyState === WebSocket.OPEN) {
      ws.current.send(JSON.stringify(messagePayload));
    } else {
      console.error('[SalesChatWidget] WebSocket not ready');
      handleError('Connection not ready. Please wait a moment and try again.');
      return;
    }

    if (!content) {
      setInputMessage('');
      if (inputRef.current) {
        inputRef.current.style.height = 'auto';
      }
    }
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      sendMessage();
    }
  };

  const sendTranscriptAsMessage = (text: string) => {
    if (!text.trim() || !ws.current || ws.current.readyState !== WebSocket.OPEN) return;

    const message: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: text,
      timestamp: new Date(),
      isVoice: true
    };

    setMessages(prev => [...prev, message]);
    setIsBusy(true);
    messageStartTimeRef.current = Date.now();

    ws.current.send(JSON.stringify({
      type: 'message',
      message: text,
      session_id: sessionId,
      max_tokens: 2000  // Allow longer responses for sales conversations (default was 500)
    }));
  };

  useEffect(() => {
    sendMessageRef.current = sendTranscriptAsMessage;
  }, [sessionId]);

  const startVoiceRecording = async () => {
    if (!recognition) return;

    if (isRecording) {
      console.log('Manually stopping recording');

      if (silenceTimerRef.current) clearTimeout(silenceTimerRef.current);
      if (pauseTimerRef.current) clearTimeout(pauseTimerRef.current);

      if (pendingTranscriptRef.current && pendingTranscriptRef.current.trim()) {
        sendMessage(pendingTranscriptRef.current.trim());
      }

      recognition.stop();
    } else {
      console.log('Starting recording');

      // Auto-enable speaker when user starts voice input for better UX
      if (!isSpeakerEnabled) {
        setIsSpeakerEnabled(true);
        localStorage.setItem('salesChatWidgetTTSEnabled', 'true');
        console.log('ğŸ”Š Auto-enabled speaker for voice input');
      }

      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
        setIsSpeaking(false);
      }
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
      }

      setTranscript('');
      setLiveTranscript('');
      pendingTranscriptRef.current = '';

      recognition.start();
      setIsRecording(true);
      setIsTranscribing(true);
      setVoiceState('recording');
      lastSpeechTimeRef.current = Date.now();
    }
  };

  const handleToggleSpeaker = () => {
    const newState = !isSpeakerEnabled;
    setIsSpeakerEnabled(newState);

    if (!newState) {
      // Stop any currently playing audio
      if (currentAudioRef.current) {
        currentAudioRef.current.pause();
        currentAudioRef.current = null;
        setIsSpeaking(false);
      }
      console.log('ğŸ”‡ Speaker manually disabled');
    } else {
      console.log('ğŸ”Š Speaker manually enabled');
    }

    localStorage.setItem('salesChatWidgetTTSEnabled', newState.toString());
  };

  const formatTime = (date: Date) => {
    return date.toLocaleTimeString('en-US', {
      hour: '2-digit',
      minute: '2-digit'
    });
  };

  return (
    <>
      {/* Floating Chat Button */}
      {!isOpen && (
        <button
          onClick={() => setIsOpen(true)}
          className="fixed bottom-6 right-6 bg-gradient-to-r from-green-600 to-emerald-600 hover:from-green-700 hover:to-emerald-700 text-white rounded-full p-4 shadow-lg hover:shadow-xl transition-all duration-300 group z-50"
          aria-label="Open sales chat"
        >
          <MessageCircle className="h-6 w-6 group-hover:scale-110 transition-transform" />
          <span className="absolute -top-2 -right-2 bg-red-500 text-white text-xs rounded-full px-2 py-0.5 animate-pulse">
            Questions?
          </span>
        </button>
      )}

      {/* Chat Window */}
      {isOpen && (
        <div
          className="fixed bottom-6 right-6 w-[520px] bg-white rounded-2xl shadow-2xl transition-all duration-300 flex flex-col z-50"
          style={{
            height: isMinimized ? '64px' : '650px'
          }}
        >
          {/* Header */}
          <div className="bg-gradient-to-r from-green-600 to-emerald-600 px-5 py-4 rounded-t-2xl flex items-center justify-between">
            <div className="flex items-center space-x-3">
              {/* Human-like avatar with initial */}
              <div className="relative">
                <div className="h-10 w-10 rounded-full bg-white/20 backdrop-blur-sm flex items-center justify-center text-white font-semibold text-lg border-2 border-white/30">
                  C
                </div>
                <span className={`absolute -bottom-0.5 -right-0.5 h-3 w-3 rounded-full border-2 border-green-600 ${
                  isConnected ? 'bg-green-300' : 'bg-gray-400'
                }`} />
              </div>
              <div>
                <h3 className="font-semibold text-white text-base">Carlos</h3>
                <p className="text-xs text-green-50 flex items-center gap-1.5">
                  {isBusy ? (
                    <>
                      <span className="inline-block w-1.5 h-1.5 bg-green-200 rounded-full animate-pulse" />
                      <span>typing...</span>
                    </>
                  ) : isConnected ? (
                    <>
                      <span className="inline-block w-1.5 h-1.5 bg-green-300 rounded-full" />
                      <span>Online</span>
                    </>
                  ) : (
                    'Connecting...'
                  )}
                </p>
              </div>
            </div>
            <div className="flex items-center space-x-1">
              <button
                onClick={() => setIsMinimized(!isMinimized)}
                className="p-1.5 hover:bg-white/20 rounded-lg transition-colors"
                aria-label="Minimize"
              >
                <Minimize2 className="h-4 w-4 text-white" />
              </button>
              <button
                onClick={() => {
                  setIsOpen(false);
                  if (ws.current) {
                    ws.current.close();
                  }
                }}
                className="p-1.5 hover:bg-white/20 rounded-lg transition-colors"
                aria-label="Close"
              >
                <X className="h-4 w-4 text-white" />
              </button>
            </div>
          </div>

          {!isMinimized && (
            <>
              {/* Messages Area */}
              <div className="flex-1 overflow-y-auto p-4 space-y-3 bg-gray-50">
                {messages.map((message) => (
                  <div key={message.id}>
                    <div className={`flex ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                      <div
                        className={`max-w-[90%] rounded-2xl px-4 py-3 ${
                          message.role === 'user'
                            ? 'bg-gradient-to-r from-green-500 to-emerald-600 text-white'
                            : message.role === 'assistant'
                            ? 'bg-white text-gray-800 shadow-md border border-gray-100'
                            : 'bg-yellow-100 text-yellow-800'
                        }`}
                      >
                        <div className="flex flex-col gap-1">
                          {/* Remove bot icon for human feel - just show content */}
                          {message.role === 'user' && message.isVoice && (
                            <div className="flex items-center gap-1.5 mb-1 opacity-70">
                              <Volume2 className="h-3 w-3" />
                              <span className="text-xs">Voice message</span>
                            </div>
                          )}
                          <div>
                            {message.role === 'assistant' ? (
                              <div 
                                className="text-[15px] leading-relaxed"
                                dangerouslySetInnerHTML={{
                                  __html: renderMarkdown(
                                    typingMessages.has(message.id)
                                      ? typingMessages.get(message.id)!
                                      : message.content
                                  )
                                }}
                              />
                            ) : (
                              <p className="whitespace-pre-wrap text-[15px] leading-relaxed">
                                {message.content}
                              </p>
                            )}
                            {/* Show cursor during typing animation */}
                            {message.role === 'assistant' && typingMessages.has(message.id) && (
                              <span className="inline-block w-0.5 h-4 ml-1 bg-green-600 animate-pulse" />
                            )}
                          </div>
                        </div>
                      </div>
                    </div>
                    {/* Timestamp with Response Time and Tokens */}
                    <div className={`mt-1.5 px-2 flex items-center gap-1.5 ${message.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                      <Clock className="h-3 w-3 text-gray-400" />
                      <span className="text-xs text-gray-500">
                        {formatTime(message.timestamp)}
                      </span>

                      {/* Show response time for assistant messages */}
                      {message.role === 'assistant' && message.responseTime !== undefined && (
                        <>
                          <span className="text-gray-300">â€¢</span>
                          <span className="text-xs text-green-600 font-medium">
                            {message.responseTime > 0 ? message.responseTime.toFixed(2) : '< 0.01'}s
                          </span>
                        </>
                      )}

                      {/* Show tokens for assistant messages */}
                      {message.role === 'assistant' && message.tokens !== undefined && message.tokens > 0 && (
                        <>
                          <span className="text-gray-300">â€¢</span>
                          <span className="text-xs text-blue-600 font-medium">
                            {message.tokens} tokens
                          </span>
                        </>
                      )}
                    </div>
                  </div>
                ))}

                {/* Typing Indicator - Human-like */}
                {isTyping && (
                  <div className="flex justify-start">
                    <div className="bg-white rounded-2xl px-4 py-3 shadow-md border border-gray-100 max-w-[90%]">
                      <div className="flex items-center gap-3">
                        <span className="text-base">{currentActivity.icon}</span>
                        <span className="text-sm text-gray-600">{currentActivity.text}</span>
                        <div className="flex space-x-1">
                          <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce" style={{ animationDelay: '0ms' }} />
                          <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce" style={{ animationDelay: '150ms' }} />
                          <div className="w-2 h-2 bg-green-500 rounded-full animate-bounce" style={{ animationDelay: '300ms' }} />
                        </div>
                      </div>
                    </div>
                  </div>
                )}

                <div ref={messagesEndRef} />
              </div>

              {/* Voice Status */}
              {isRecording && (transcript || liveTranscript) && (
                <div className="bg-gray-100 px-4 py-3 border-t border-gray-200">
                  <div className="p-2 bg-white rounded-lg border border-gray-200">
                    <div className="text-xs text-gray-500 mb-1 flex items-center gap-1">
                      <span className="animate-pulse text-red-500">â—</span> Live Transcript
                    </div>
                    <div className="text-sm text-gray-800">{transcript || liveTranscript}</div>
                    <div className="text-xs text-gray-400 mt-1 italic">
                      (Pause 2s to send â€¢ 2s silence to stop)
                    </div>
                  </div>
                </div>
              )}

              {/* Input Area */}
              <div className="border-t border-gray-200 p-4 bg-white rounded-b-2xl">
                <div className="flex items-end space-x-2">
                  <div className="flex-1 relative">
                    <textarea
                      ref={inputRef}
                      value={inputMessage}
                      onChange={(e) => setInputMessage(e.target.value)}
                      onKeyPress={handleKeyPress}
                      placeholder={
                        isBusy
                          ? "Carlos is thinking..."
                          : isRecording
                          ? "Recording voice..."
                          : isConnected
                          ? "Ask about pricing, features, or getting started..."
                          : "Connecting..."
                      }
                      disabled={!isConnected || isBusy || isRecording}
                      rows={1}
                      className="w-full px-4 py-3 pr-12 border border-gray-300 rounded-xl resize-none focus:outline-none focus:ring-2 focus:ring-green-500 disabled:opacity-50 disabled:cursor-not-allowed text-[15px] transition-colors"
                      style={{ maxHeight: '150px', minHeight: '44px' }}
                      onInput={(e) => {
                        const target = e.target as HTMLTextAreaElement;
                        target.style.height = 'auto';
                        target.style.height = Math.min(target.scrollHeight, 150) + 'px';
                      }}
                    />
                  </div>

                  {/* Voice Button */}
                  {enableVoice && voicePermission && (
                    <button
                      onClick={startVoiceRecording}
                      disabled={!isConnected || isBusy}
                      className={`p-2.5 rounded-xl transition-all ${
                        isRecording
                          ? 'bg-red-500 hover:bg-red-600 text-white animate-pulse'
                          : isTranscribing
                          ? 'bg-yellow-500 text-white'
                          : 'bg-gray-100 hover:bg-gray-200 text-gray-600'
                      } disabled:opacity-30 disabled:cursor-not-allowed`}
                      aria-label={isRecording ? 'Stop recording' : 'Start voice recording'}
                    >
                      {isRecording ? (
                        <MicOff className="h-5 w-5" />
                      ) : isTranscribing ? (
                        <Loader2 className="h-5 w-5 animate-spin" />
                      ) : (
                        <Mic className="h-5 w-5" />
                      )}
                    </button>
                  )}

                  {/* Speaker Button */}
                  <button
                    onClick={handleToggleSpeaker}
                    className={`p-2.5 rounded-xl transition-all ${
                      isSpeakerEnabled
                        ? isSpeaking
                          ? 'bg-green-500 text-white animate-pulse'
                          : 'bg-green-500 hover:bg-green-600 text-white'
                        : 'bg-gray-100 hover:bg-gray-200 text-gray-600'
                    }`}
                    aria-label={isSpeakerEnabled ? 'Disable text-to-speech' : 'Enable text-to-speech'}
                  >
                    {isSpeakerEnabled ? (
                      <Volume2 className="h-5 w-5" />
                    ) : (
                      <VolumeX className="h-5 w-5" />
                    )}
                  </button>

                  {/* Send Button */}
                  <button
                    onClick={() => sendMessage()}
                    disabled={!isConnected || !inputMessage.trim() || isBusy || isRecording}
                    className="p-2.5 bg-gradient-to-r from-green-500 to-emerald-600 hover:from-green-600 hover:to-emerald-700 text-white rounded-xl disabled:opacity-30 disabled:cursor-not-allowed transition-all"
                    aria-label="Send message"
                  >
                    <Send className="h-5 w-5" />
                  </button>
                </div>

                {/* Status Bar */}
                <div className="flex items-center justify-between mt-2">
                  <div className="flex items-center gap-2">
                    {!isConnected && (
                      <span className="text-xs text-orange-600 flex items-center gap-1">
                        <AlertCircle className="h-3 w-3" />
                        Reconnecting...
                      </span>
                    )}
                    {isBusy && (
                      <span className="text-xs text-green-600 flex items-center gap-1">
                        <Loader2 className="h-3 w-3 animate-spin" />
                        Processing...
                      </span>
                    )}
                    {voiceState === 'error' && (
                      <span className="text-xs text-red-600">
                        Voice recognition error. Please try again.
                      </span>
                    )}
                  </div>
                  <span className="text-xs text-gray-500 italic">
                    Powered by WeedGo AI
                  </span>
                </div>
              </div>
            </>
          )}
        </div>
      )}
    </>
  );
};

export default SalesChatWidget;
